{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Introduction\n",
        "\n",
        "Load the Google Drive folder and install `simpletransformer`"
      ],
      "metadata": {
        "id": "Kr1hFWG-vp9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRkFlnud-grt"
      },
      "outputs": [],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MBg0F8S-iWZ",
        "outputId": "a26613eb-c187-40c8-f2e9-3bc8f0c08688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NaiveBayes\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/NaiveBayes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Data\n",
        "\n",
        "Load the source data and create training and testing datasets."
      ],
      "metadata": {
        "id": "KSTbasepwF70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwFl2Rhb-nDS",
        "outputId": "7c07eed3-3b7c-4629-8953-47bc52bf3414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Data: 24480\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_folder = '../source_data'\n",
        "\n",
        "def extract_sentences(text):\n",
        "    sentences = re.split(r'\\.', text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "sentences, labels = [], []\n",
        "\n",
        "for class_folder in os.listdir(data_folder):\n",
        "    class_path = os.path.join(data_folder, class_folder)\n",
        "    if not os.path.isdir(class_path) or class_folder.startswith('.'):\n",
        "        continue\n",
        "    for doc_file in os.listdir(class_path):\n",
        "        doc_path = os.path.join(class_path, doc_file)\n",
        "        with open(doc_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "            doc_sentences = extract_sentences(text)\n",
        "            sentences.extend(doc_sentences)\n",
        "            labels.extend([class_folder] * len(doc_sentences))\n",
        "\n",
        "label_to_int = {'LETTA Enrico': 0, 'MELONI Giorgia': 1, 'CONTE Giuseppe': 2, 'DRAGHI Mario': 3, 'RENZI Matteo': 4, 'GENTILONI SILVERI Paolo': 5}\n",
        "int_to_label = {value:key for key,value in label_to_int.items()}\n",
        "\n",
        "\n",
        "print('Number of Training Data:', len(sentences))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.1, stratify=labels, random_state=1946)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train and Evaluate a NaiveBayes classifier\n",
        "\n",
        "Create classification NaiveBayes classifier using `scikit-learn`."
      ],
      "metadata": {
        "id": "cklw79c8xPGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classifier = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=100000)),\n",
        "    ('nb', MultinomialNB(alpha=0.01))\n",
        "])\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_proba = classifier.predict_proba(X_test)\n",
        "\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "C2A5cUYebKk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f13bb9-eb7e-483c-8727-055f60271007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "         CONTE Giuseppe       0.82      0.88      0.85       829\n",
            "           DRAGHI Mario       0.67      0.58      0.62       266\n",
            "GENTILONI SILVERI Paolo       0.70      0.56      0.62       139\n",
            "           LETTA Enrico       0.66      0.52      0.59       242\n",
            "         MELONI Giorgia       0.80      0.87      0.83       690\n",
            "           RENZI Matteo       0.74      0.74      0.74       282\n",
            "\n",
            "               accuracy                           0.77      2448\n",
            "              macro avg       0.73      0.69      0.71      2448\n",
            "           weighted avg       0.77      0.77      0.77      2448\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}